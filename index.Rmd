---
title: "Final Project"
output: html_document
---

Makai Freeman 115153547
Brian Murray 114120922
Chukwuemeka Okeke 114585332

# Introduction

This is a tutorial created for our final project for CMSC320 (Introduction to Data Science) at the University of Maryland. This tutorial is a walkthrough the data science pipeline. This includes data curation, parsing, and management; exploratory data analysis; hypothesis testing and machine learning to provide analysis; and the curation of a message covering insights learned during the tutorial. 

To complete this tutorial, we use listings from Airbnb in the Washington D.C. area. The ultimate goal is to use the pipeline mentioned above to predict the cost of future listings in the area.  

First we need some packages. 
###### NEED TO ADD THE PACKAGES THAT WE USE AND A SHORT DESCRUPTION #########

```{r load_data, message=FALSE}
library(readr)
library(dplyr)
library(tidyverse)
library(leaflet)
library(stringi)
library(stringr)
```

# 1. Data Curation, Parsing, and Management

First we want to find suitable data, we used data straight from Airbnb. 
Then we want to download the data from the website. This is done using the "read_csv" function as the file we want to download is a csv (Comma-separated values).
```{r load data, message=FALSE}
abnb <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2019-04-15/visualisations/listings.csv")

head(abnb)
```
This downloads the data and stores it as a tibble with the name "abnb."

Next we want to take this data and manipulate it a bit. To do this, we want to remove the values that we will not need. In our case, it is the columns "neighbourhood_group", "last_review", and "reviews_per_month."

We will use the functions 
select()
%>%

```{r convert}

abnb <- abnb %>% 
  select(-"neighbourhood_group", -"last_review", -"reviews_per_month")

head(abnb)
```

This takes the previous tibble and removes the columns that we will not be using. 


# 2. Exploratory Data Analysis
Next we move into exploratory data analysis. Exploratory data analysis is the investigation of variables across observations. We want to spot any issues with our data, explore variable properties, and look at possible models for our data. 



We will begin with a display of each distribution for our variables. 

To do this, we use the functions
####################################################################################
ggplot() (and the geom functions related)
%>% 

# Part A
```{r availability}
abnb %>%
  ggplot(aes(x = availability_365)) +
  geom_histogram(binwidth = 50)
```

This histogram explores the number of days each listing is available. The possible values are from 0-365. Since we only want listings that are available we will remove all of the listings that have 0 days available and replot. 


```{r availability remove 0}  
# updates the variable so the availability is at least 1 day
abnb <- abnb[abnb$availability_365 > 0,]

abnb %>%
  ggplot(aes(x = availability_365)) +
  geom_histogram(binwidth = 50)

```

This plot is much more even than before. The data seems to be bimodal with peaks around 50-100 and 300+. The latter makes sense as there are likely many locations that are available 365 days a year.

```{r neighborhoods}

abnb %>%
  group_by(neighbourhood) %>%
  summarize(neigh_count = n()) %>%
  ggplot(aes(x=reorder(neighbourhood, -neigh_count), y=neigh_count)) +
  geom_bar(stat = "identity") +
  labs(x="Neighborhood", y="Count") +
  coord_flip() 

```
This plot shows the number of listings that are in each neighborhood in Washington, D.C.. Capitol Hill, Lincoln Park has the most listings with 610. 

```{r price}
abnb %>% 
  ggplot(aes(x = price)) + 
  geom_histogram(bins = 100) +
  scale_x_log10()
```
This plot shows the spread of prices for Washington D.C. listings. We use a logarithmic scale for this because there is a huge outlier as one listing has a price of $10,000. 


```{r min_nights}

abnb %>% 
  ggplot(aes(x = minimum_nights)) + 
  geom_histogram(binwidth = .25) +
  scale_x_log10()

```
This graph shows the spread of minimum number of nights required by listings in Washington D.C.. We also use a logorithmic scale as there is an outlier at 600+ minimum nights. 


# Part B

```{r price by room}

abnb %>%
  ggplot(aes(x= room_type, y = price)) +
  geom_violin(draw_quantiles = .5) +
  scale_y_log10()

```

This plot is a violin plot with the median drawn as a horizontal line. From this plot we can see a possible correlation between price and type of room.

```{r neighborhood price}

abnb %>%
  group_by(neighbourhood) %>%
  summarize(neigh_med = median(price)) %>%
  ggplot(aes(x=reorder(neighbourhood, -neigh_med), y=neigh_med)) +
  geom_point() +
  labs(x="Neighborhood", y="Price per Night") +
  coord_flip() 
```


# 3. Hypothesis testing

As we continue with our analysis, we are going to need more data to make predictions about the future of these listings on Airbnb. Our current data was collected in April 2019, we will add data that was compiled between April 2018 and April 2019 in order to look at changes over time so that we can make predictions about the future. 

We will also use the data that is previously compiled to decide if neighborhood has an affect on price. 

```{r load new data, message=FALSE}
abnb$date_compiled <- as.Date("2019-04-01")

a18 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2018-04-15/visualisations/listings.csv")
a18$date_compiled <- as.Date("2018-04-01")

m18 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2018-05-18/visualisations/listings.csv")
m18$date_compiled <- as.Date("2018-05-01")

j18 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2018-07-20/visualisations/listings.csv")
j18$date_compiled <- as.Date("2018-07-01")

aug18 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2018-08-18/visualisations/listings.csv")
aug18$date_compiled <- as.Date("2018-08-01")

s18 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2018-09-14/visualisations/listings.csv")
s18$date_compiled <- as.Date("2018-09-01")

o18 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2018-10-12/visualisations/listings.csv")
o18$date_compiled <- as.Date("2018-10-01")

n18 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2018-11-15/visualisations/listings.csv")
n18$date_compiled <- as.Date("2018-11-01")

d18 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2018-12-13/visualisations/listings.csv")
d18$date_compiled <- as.Date("2018-12-01")

j19 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2019-01-17/visualisations/listings.csv")
j19$date_compiled <- as.Date("2019-01-01")

f19 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2019-02-11/visualisations/listings.csv")
f19$date_compiled <- as.Date("2019-02-01")

m19 <- read_csv("http://data.insideairbnb.com/united-states/dc/washington-dc/2019-03-12/visualisations/listings.csv")
m19$date_compiled <- as.Date("2019-03-01")

abnb <- rbind(abnb, a18, m18, j18, aug18, s18, o18, n18, d18, j19, f19, m19)
abnb <- abnb[abnb$availability_365 > 0,]
head(abnb)
```

```{r map, message=FALSE}

icons <- awesomeIcons(
  markerColor = getColor(abnb)
)
abnbmap <- leaflet(abnb) %>%
  addTiles() %>%
  addAwesomeMarkers(icon = icons, clusterOptions = markerClusterOptions(), label = ~as.character(name), popup = ~as.character(price)) %>%
   setView(lat=38.9072, lng=-77.0369, zoom=12)
abnbmap
```














```{r blah}

abnb %>% 
  arrange(date_compiled) %>%
  group_by(date_compiled) %>%
  summarise(qw = mean(price)) %>%
  ggplot(aes(x = date_compiled, y = qw)) +
  geom_point() +
  geom_smooth(method = lm)
  

```








